# üéØ Verbalized Sampling in Your Outreach Agent

## What is Verbalized Sampling?

**Problem:** LLMs suffer from "mode collapse" - they always give the most typical/generic response.

**Solution:** Verbalized Sampling asks the LLM to:
1. Generate **5 different responses** (not just 1)
2. Assign a **probability** to each
3. **Sample from the "tails"** (low-probability, more creative options)
4. Pick the **best variant**

**Result:** 1.6-2.1x more creative, diverse outputs while maintaining quality.

Source: [verbalized-sampling.com](https://www.verbalized-sampling.com)

---

## Why This is PERFECT for Your Agency

### Before (Generic):
```
Hi John, I noticed you're a VP at TechCorp and wanted to reach out
about potential synergies. Would love to connect!
```
‚òπÔ∏è Could be sent to anyone

### After (Verbalized Sampling):
```
Variant 1: "John - your post about RAG scaling hit home. We're wrestling
with the same 100M+ query bottlenecks. Coffee to compare notes?"

Variant 2: "Saw your AI Summit talk on vector DB optimization. That
1B QPS stat was wild. Quick call about productionizing LLMs?"

Variant 3: "John, TechCorp's $50M Series B seems timed perfectly for
that hiring push. Love to chat about ML infrastructure challenges."

Variant 4: "Your Meta experience with rec systems is impressive.
Working on similar scale problems. 15 min to exchange war stories?"

Variant 5: "Posted about the same vector DB challenges you mentioned.
DataScale must be hiring like crazy. Coffee in SF next week?"
```

‚úÖ Supervisor picks the best one (most specific, natural, relevant)

---

## How It Works in Your Code

### 1. Generate Variants (prompts.yaml)
```yaml
tools:
  generate_message_variants: |
    <instructions>
    Generate 5 different personalized LinkedIn outreach messages.
    Each must have a <message> and <probability>.
    Sample from tails of distribution (probability < 0.10).
    Make them DIVERSE - different hooks, angles, tones.
    </instructions>

    PROFILE: {profile_data}
    RESEARCH: {research_data}

    VARY THESE:
    - Opening hook (question vs observation vs compliment)
    - Which profile detail to emphasize
    - Which research insight to lead with
    - Tone/formality
    - CTA style
```

### 2. Select Best (prompts.yaml)
```yaml
tools:
  select_best_message: |
    Pick the BEST message from variants.

    CRITERIA:
    1. Specificity - concrete details, not generic
    2. Relevance - timely research insight
    3. Natural tone - human, not template
    4. Strong hook - compelling opening
    5. Clear CTA - obvious next step
```

### 3. Workflow (production_simple.py)
```python
# Step 1: Scrape profile
profile = scrape_linkedin_profile(url)

# Step 2: Research company
research = research_company(company)

# Step 3: Generate 5 variants (Verbalized Sampling)
variants = generate_message_variants(profile, research)

# Step 4: Supervisor picks best
selected = select_best_message(variants, profile, research)
```

---

## What You Get

### Output Format:
```
SELECTED MESSAGE:
Hey Sarah! Saw your AI Infrastructure Summit talk on scaling vector
DBs‚Äîthe query optimization for 1B+ QPS was mind-blowing. DataScale's
$50M Series B seems perfectly timed for your hiring push. Coffee in
SF to chat about productionizing LLM infrastructure?

WHY THIS ONE (Score: 9/10):
Most specific references (named the conference, cited exact metric,
included funding amount/timing). Natural peer-to-peer tone. Strong
hook with the 1B+ QPS stat. Clear, casual CTA.

WHY NOT OTHERS:
Variant 1 was too generic (just mentioned "ML experience")
Variant 2 had weak CTA ("let me know")
Variant 3 too formal ("I hope this finds you well")
Variant 4 too sales-y ("explore synergies")
```

---

## Benefits for Your Agency

### 1. Non-Generic Messages
- Each profile gets 5 unique variants generated
- Supervisor picks most specific/relevant
- No two people get the same template

### 2. Easy A/B Testing
```yaml
# Client A prefers casual
message_rules:
  tone: "casual and friendly"
  cta_style: "casual coffee chat"

# Client B prefers professional
message_rules:
  tone: "professional but approachable"
  cta_style: "15-min quick call"
```

### 3. Better Response Rates
- Research shows 1.6-2.1x more creative outputs
- More specific = higher reply rates
- Less "spammy" feeling

### 4. Non-Dev Friendly
Your account manager can tweak prompts in `prompts.yaml`:
```yaml
# Add constraint to variants
VARY THESE:
- Opening hook
- Which profile detail to emphasize
- Emoji usage (yes/no)  # <-- They added this!
```

---

## Tweaking for Your Clients

### More Conservative (Safer):
```yaml
# prompts.yaml
tools:
  generate_message_variants: |
    Generate 3 variants (instead of 5)
    Keep tone professional across all variants
    Focus on: recent company news, mutual interests, clear value prop
```

### More Aggressive (Creative):
```yaml
tools:
  generate_message_variants: |
    Generate 7 variants (instead of 5)
    Try different: questions, compliments, insights, humor
    Experiment with: emojis, casual language, bold claims
```

### Industry-Specific:
```yaml
# For tech startups
tools:
  generate_message_variants: |
    Emphasize: funding rounds, product launches, technical challenges
    Tone: casual, peer-to-peer
    CTA: coffee, quick call

# For finance/corporate
tools:
  generate_message_variants: |
    Emphasize: market trends, regulatory changes, efficiency gains
    Tone: professional, respectful of hierarchy
    CTA: formal meeting, scheduled call
```

---

## Cost Impact

### Single Message (Before):
- 1 LLM call to generate = ~500 tokens
- Cost: $0.005 (with GPT-4o)

### Verbalized Sampling (After):
- 1 LLM call to generate 5 variants = ~2500 tokens
- 1 LLM call to select best = ~500 tokens
- Cost: $0.025 (with GPT-4o)

**5x cost, but 2x better quality** = Worth it for B2B outreach

### Cost Optimization:
```yaml
# config.yaml - use cheaper model for generation
models:
  generator:
    model: "gpt-4o-mini"  # 10x cheaper, still good quality
    temperature: 0.8  # Slightly higher for diversity
```

---

## When to Use Verbalized Sampling

### ‚úÖ USE when:
- B2B outreach where personalization matters
- High-value prospects (VPs, C-suite)
- You want to stand out from generic templates
- Response rate matters more than cost
- Testing different messaging angles

### ‚ùå DON'T USE when:
- Mass outreach (1000s of profiles)
- Low-value prospects
- Cost is the primary concern
- You want predictable, consistent messaging
- Simple templates work fine

---

## Advanced: Show All Variants to User

Want your team to manually pick instead of auto-select?

```python
# production_simple.py - add this function

def generate_variants_for_review(linkedin_url: str) -> Dict[str, Any]:
    """Generate variants and return all 5 for manual review."""
    # ... scrape and research ...

    variants = generate_message_variants(profile, research)

    # Parse variants (you'd implement XML parsing)
    parsed = parse_variants(variants)

    # Show all 5 to user
    print("\n===== 5 VARIANTS =====")
    for i, v in enumerate(parsed, 1):
        print(f"\n--- VARIANT {i} (p={v.probability}) ---")
        print(v.message)
        print(f"Hook: {v.hook_type}")

    # Manual selection
    choice = input("\nPick 1-5 (or 0 for auto-select): ")

    if choice == "0":
        selected = select_best_message(variants, profile, research)
    else:
        selected = parsed[int(choice)-1].message

    return {"message": selected}
```

---

## Testing the Improvement

### Quick Test:
```bash
# Generate 10 messages WITHOUT verbalized sampling
python old_version.py --urls test_urls.txt --output old.csv

# Generate 10 messages WITH verbalized sampling
python production_simple.py --urls test_urls.txt --output new.csv

# Compare specificity, diversity, quality
# Ask your team: which set is better?
```

### Metrics to Track:
- **Specificity score**: How many concrete details per message?
- **Diversity**: How different are messages for similar profiles?
- **Response rate**: % who reply (the real test!)
- **Quality feedback**: Show clients both versions

---

## Questions?

**Q: Why not always generate variants?**
A: Cost. 5x more expensive per message. Use for high-value outreach.

**Q: Can I use fewer than 5 variants?**
A: Yes! Change the prompt to "Generate 3 variants". Saves cost.

**Q: Does it work with gpt-4o-mini?**
A: Yes, but quality drops slightly. Test it!

**Q: Can the supervisor pick poorly?**
A: Rarely. The selection criteria are strict. You can review before sending.

**Q: How do I know it's working?**
A: Check the output - you'll see "WHY THIS ONE" explanation. If it's always picking variant 1, something's wrong.

---

## TL;DR

**Before:** Generate 1 message ‚Üí hope it's good

**After:** Generate 5 diverse variants ‚Üí supervisor picks best ‚Üí guaranteed non-generic

Perfect for agencies that need:
- ‚úÖ Personalized messages at scale
- ‚úÖ Non-dev team can tweak prompts
- ‚úÖ Quality over quantity
- ‚úÖ Stand out from generic templates

**Cost:** 5x per message
**Quality:** 2x better
**Worth it?** For B2B outreach, YES.
